{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6HmksBlkYC7-"
      },
      "outputs": [],
      "source": [
        "# Python standard library packages to do file/folder manipulations,\n",
        "# pickle is a package to store python variables\n",
        "import glob, os, pickle, sys\n",
        "\n",
        "# time grabs current clock time and copy to safely make copies of large \n",
        "# variables in memory.\n",
        "import time, copy \n",
        "\n",
        "# datetime package is used to get and manipulate date and time data\n",
        "from datetime import datetime\n",
        "\n",
        "# this packages helps load and save .mat files older than v7\n",
        "import hdf5storage \n",
        "\n",
        "# numpy works with arrays, pandas used to work with fancy numpy arrays\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# matplotlib is used to plot and animate to make movies\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "\n",
        "# moviepy helps open the video files in Python\n",
        "from moviepy.editor import VideoClip, VideoFileClip\n",
        "from moviepy.video.io.bindings import mplfig_to_npimage\n",
        "\n",
        "# Scikit-learn is a go-to library in Python for all things machine learning\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# tqdm helps create progress bars in for loops \n",
        "from tqdm import tqdm \n",
        "\n",
        "# Scipy is a go-to scientific computing library. We'll use it for median filtering. \n",
        "from scipy.ndimage import median_filter\n",
        "\n",
        "# Configuring matplotlib to show animations in a colab notebook as javascript \n",
        "# objects for easier viewing. \n",
        "from matplotlib import rc\n",
        "rc('animation', html='jshtml')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhuNfeVm4T1P"
      },
      "source": [
        "# Creating an mmpy project directory\n",
        "\n",
        "Now that we have two low dimensional time series which **may** not set Google servers on fire, we will create our project directory for running the `motionmapperpy` pipeline on the data we have. Having a project directory is awesome, as it helps us stay organized when working with big datasets and multiple files. It allows datasets to be easily referenced and loaded without exhausting memory, and we can store pipeline outputs in well-defined and easy to read files.\n",
        "\n",
        "\n",
        "Lets start by importing `motionmapperpy` and creating a project directory. We've already created this, so no need to do anything beside set path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "smnR7O9Y4idG"
      },
      "outputs": [],
      "source": [
        "import motionmapperpy as mmpy\n",
        "\n",
        "\n",
        "projectPath = 'mmpy_lts_all'\n",
        "\n",
        "# This creates a project directory structure which will be used to store all motionmappery pipeline\n",
        "# related data in one place.\n",
        "\n",
        "# mmpy.createProjectDirectory(projectPath)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_uosHZN5mqS"
      },
      "source": [
        "Now lets store the two low-d time series in **projs_list** to the *`Projections`* folder in the project directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDOKMsD15_l-"
      },
      "outputs": [],
      "source": [
        "# for i,projs in enumerate(projs_list):\n",
        "#     hdf5storage.savemat('%s/Projections/%s_pcaModes.mat'%(projectPath, datasetnames[i]), {'projections':projs})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocFZeYek6gO_"
      },
      "source": [
        "We'll now go through `mmpy` parameters. They are a handful and can be overwhelming, but they are very easy to understand! \n",
        "\n",
        "Parameters are cruicial to `mmpy` as they lay out some hard-coded choices we need to make when running this pipeline. I will explain each parameter as we encounter them in the cell below, so please read through this cell below as you run it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U_QuCClWcDHm"
      },
      "outputs": [],
      "source": [
        "\"\"\"2. Setup run parameters for MotionMapper.\"\"\"\n",
        "\n",
        "#% Load the default parameters.\n",
        "parameters = mmpy.setRunParameters() \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lWC2PbfYnG6X"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'numProcessors': 16,\n",
              " 'numPeriods': 25,\n",
              " 'omega0': 5,\n",
              " 'samplingFreq': 100,\n",
              " 'minF': 1,\n",
              " 'maxF': 50,\n",
              " 'tSNE_method': 'barnes_hut',\n",
              " 'perplexity': 32,\n",
              " 'embedding_batchSize': 128000,\n",
              " 'maxOptimIter': 500,\n",
              " 'trainingSetSize': 64000,\n",
              " 'maxNeighbors': 200,\n",
              " 'kdNeighbors': 5,\n",
              " 'training_perplexity': 20,\n",
              " 'training_numPoints': 32000,\n",
              " 'minTemplateLength': 1,\n",
              " 'waveletDecomp': True,\n",
              " 'useGPU': -1,\n",
              " 'n_neighbors': 15,\n",
              " 'train_negative_sample_rate': 5,\n",
              " 'embed_negative_sample_rate': 1,\n",
              " 'min_dist': 0.1,\n",
              " 'umap_output_dims': 2,\n",
              " 'n_training_epochs': 100,\n",
              " 'rescale_max': 100,\n",
              " 'method': 'TSNE',\n",
              " 'projectPath': 'mmpy_lts_1d'}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5866VHTOlTL3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 48 projection files\n",
            "Project path: mmpy_lts_1d\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# %%%%%%% PARAMETERS TO CHANGE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "# These need to be revised everytime you are working with a new dataset. #\n",
        "import glob\n",
        "import h5py\n",
        "import natsort\n",
        "parameters.projectPath = 'mmpy_lts_1d'#parameters.projectPath #% Full path to the project directory.\n",
        "\n",
        "\n",
        "parameters.method = 'TSNE' #% We can choose between 'TSNE' or 'UMAP'\n",
        "\n",
        "parameters.minF = 1        #% Minimum frequency for Morlet Wavelet Transform\n",
        "\n",
        "parameters.maxF = 50       #% Maximum frequency for Morlet Wavelet Transform,\n",
        "                           #% usually equal to the Nyquist frequency for your\n",
        "                           #% measurements.\n",
        "\n",
        "parameters.samplingFreq = 100    #% Sampling frequency (or FPS) of data.\n",
        "\n",
        "parameters.numPeriods = 25       #% No. of dyadically spaced frequencies to\n",
        "                                 #% calculate between minF and maxF.\n",
        "projectionFiles = glob.glob(parameters.projectPath + \"/Projections/*pcaModes.mat\")\n",
        "print(\"Found {} projection files\".format(len(projectionFiles)))\n",
        "print(f\"Project path: {parameters.projectPath}\")\n",
        "projectionFiles = natsort.natsorted(projectionFiles)\n",
        "with h5py.File(projectionFiles[0], \"r\") as f:\n",
        "    m = f[\"projections\"][:].T\n",
        "# parameters.pcaModes = #comps_above_thresh #% Number of low-d features.\n",
        "parameters.pcaModes = m.shape[1]  #%Number of PCA projections in saved files.\n",
        "parameters.numProjections = parameters.pcaModes\n",
        "parameters.numProcessors = -1     #% No. of processor to use when parallel\n",
        "                                 #% processing for wavelet calculation (if not using GPU)  \n",
        "                                 #% and for re-embedding. -1 to use all cores \n",
        "                                 #% available.\n",
        "\n",
        "parameters.useGPU = 0           #% GPU to use for wavelet calculation, \n",
        "                                 #% set to -1 if GPU not present.\n",
        "\n",
        "parameters.training_numPoints = 3000    #% Number of points in mini-trainings.\n",
        "\n",
        "\n",
        "# %%%%% NO NEED TO CHANGE THESE UNLESS MEMORY ERRORS OCCUR %%%%%%%%%%\n",
        "\n",
        "parameters.trainingSetSize = 5000  #% Total number of training set points to find. \n",
        "                                 #% Increase or decrease based on\n",
        "                                 #% available RAM. For reference, 36k is a \n",
        "                                 #% good number with 64GB RAM.\n",
        "\n",
        "parameters.embedding_batchSize = 30000  #% Lower this if you get a memory error when \n",
        "                                        #% re-embedding points on a learned map.\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU8RN67i_fZe"
      },
      "source": [
        "Above covers usually relevant parameters when using `mmpy`. However, there are parameters associated with tSNE and UMAP implementations, such as below, which aren't usually required to be changed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "O3RBAwEg_75_"
      },
      "outputs": [],
      "source": [
        "# %%%%%%% tSNE parameters %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "\n",
        "#% can be 'barnes_hut' or 'exact'. We'll use barnes_hut for this tutorial for speed.\n",
        "parameters.tSNE_method = 'barnes_hut' \n",
        "\n",
        "# %2^H (H is the transition entropy)\n",
        "parameters.perplexity = 32\n",
        "\n",
        "# %number of neigbors to use when re-embedding\n",
        "parameters.maxNeighbors = 200\n",
        "\n",
        "# %local neighborhood definition in training set creation\n",
        "parameters.kdNeighbors = 5\n",
        "\n",
        "# %t-SNE training set perplexity\n",
        "parameters.training_perplexity = 20\n",
        "\n",
        "\n",
        "# %%%%%%%% UMAP Parameters %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "\n",
        "# Size of local neighborhood for UMAP.\n",
        "n_neighbors = 15\n",
        "\n",
        "# Negative sample rate while training.\n",
        "train_negative_sample_rate = 5\n",
        "\n",
        "# Negative sample rate while embedding new data.\n",
        "embed_negative_sample_rate = 1\n",
        "\n",
        "# Minimum distance between neighbors.\n",
        "min_dist = 0.1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTh2DM5L6e8E"
      },
      "source": [
        "## 3.1&nbsp; Visualizing wavelet amplitudes\n",
        "\n",
        "This section is not required to be run by motionmapperpy, but we'll go through it to visualize spectrograms on one of the low-dimensional time series.\n",
        "\n",
        "We'll use `mmpy.findWavelets` function to obtain the waveletes, and plot the obtained spectrogram for each feature/projection. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lysbx4_k61KW"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import h5py\n",
        "import natsort\n",
        "# wlets, freqs = mmpy.findWavelets(projs_list[0], projs_list[0].shape[1], parameters.omega0, parameters.numPeriods, parameters.samplingFreq, parameters.maxF, parameters.minF, parameters.numProcessors, parameters.useGPU)\n",
        "projectionFiles = glob.glob(parameters.projectPath + \"/Projections/*pcaModes.mat\")\n",
        "projectionFiles = natsort.natsorted(projectionFiles)\n",
        "projectionFile = projectionFiles[0]\n",
        "wavelet_path = f\"{parameters.projectPath}/Wavelets/{pathlib.Path(projectionFile).stem}-wavelets.mat\"\n",
        "with h5py.File(wavelet_path, \"r\") as hfile:\n",
        "    wlets = hfile[\"wavelets\"][:].T\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('frequencies.pickle', 'rb') as handle:\n",
        "    freqs = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# wlets[:600,25*i:25*(i+1)].T.shape\n",
        "# plt.imshow(wlets[:600,25*i:25*(i+1)].T, aspect='auto', cmap='jet')\n",
        "# del fig, ax\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(24, 1)\n",
        "\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "  # print(f'shape: {wlets[:1000,25*i:25*(i+1)].shape}')\n",
        "  ax.imshow(wlets[25*i:25*(i+1),:(10*100)], cmap='PuRd')\n",
        "  ax.set_yticks([0, 5, 10, 15, 20, 24])\n",
        "  ax.set_yticklabels(['%0.1f'%freqs[j] for j in [0, 5, 10, 15, 20, 24]])\n",
        "  if i == 11:\n",
        "    pass\n",
        "    # ax.set_ylabel(\"Frequencies (hz)\", fontsize=14)\n",
        "  if i != 23:\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    ax.set_xticklabels([])\n",
        "  # ax.set_title('Projection #%i'%(i+1))\n",
        "ax.set_xlabel('Frames', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"tmp2.png\",dpi=300)\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWZtyxgLBWyu"
      },
      "source": [
        "As we can see, our low-d time series is soon dwarfed by the 25-dimensional wavelet amplitudes obtained for each low-d feature! This is why its wise to spend some time reducing the dimensionality of our original data, as much as we can. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aNoAnng7Cla"
      },
      "source": [
        "# 5.&nbsp; Creating a training set and embedding it using tSNE/UMAP "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9eJ1AzK7ybU"
      },
      "source": [
        "Even though we are working with toy datasets, we have two extremely high dimensional timeseries we're using to create a smaller and more interpretable representation. tSNE and UMAP both need to compute all-to-all distances in high-dimensional space to find neighboring points and embed them closely on this low-dimensional space we're building. This computation can quickly exhaust memory (RAM) and scale exponentially with datapoints. \n",
        "\n",
        "To navigate this challenge, we do a subsampling procedure to create a training set, and use tSNE or UMAP to create training embeddings. All of this is done in the cell below.\n",
        "\n",
        "**Time taken** : TSNE 86 sec | UMAP 44 sec\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "import natsort\n",
        "import h5py\n",
        "projectionFiles = glob.glob(parameters.projectPath + \"/Projections/**pcaModes.mat\")\n",
        "projectionFiles = natsort.natsorted(projectionFiles)\n",
        "print(projectionFiles[0])\n",
        "with h5py.File(projectionFiles[0], \"r\") as f:\n",
        "    m = f[\"projections\"][:].T\n",
        "\n",
        "# %%%%%\n",
        "print(m.shape)\n",
        "parameters.pcaModes = m.shape[1]  #%Number of PCA projections in saved files.\n",
        "parameters.numProjections = parameters.pcaModes\n",
        "# %%%%%\n",
        "del m\n",
        "\n",
        "print(datetime.now().strftime(\"%m-%d-%Y_%H-%M\"))\n",
        "print(\"tsneStarted\")\n",
        "\n",
        "if parameters.method == \"TSNE\":\n",
        "    if parameters.waveletDecomp:\n",
        "        tsnefolder = parameters.projectPath + \"/TSNE/\"\n",
        "    else:\n",
        "        tsnefolder = parameters.projectPath + \"/TSNE_Projections/\"\n",
        "elif parameters.method == \"UMAP\":\n",
        "    tsnefolder = parameters.projectPath + \"/UMAP/\"\n",
        "for i in range(len(projectionFiles)):\n",
        "    if not os.path.exists(tsnefolder + \"training_tsne_embedding.mat\"):\n",
        "        print(\"Calculating wavelets...\")\n",
        "        mmpy.get_wavelets(projectionFiles, parameters, i)\n",
        "        print(datetime.now().strftime(\"%m-%d-%Y_%H-%M\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRid9ecM7q3A"
      },
      "outputs": [],
      "source": [
        "# t1 = time.time()\n",
        "\n",
        "# mmpy.subsampled_tsne_from_projections(parameters, parameters.projectPath)\n",
        "\n",
        "# print('Done in %i seconds.'%(time.time()-t1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7QH0-yOEkgZ"
      },
      "source": [
        "Note that the `training set` and `training embedding` are both save in the `project_directory/TSNE` or `project_directory/UMAP` directories depending on which method you're using. We'll load the training embedding below and plot it. You can play around with the sigma value here to change the coarseness of the density map. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXfWBg7pAx2w"
      },
      "outputs": [],
      "source": [
        "trainy = hdf5storage.loadmat('%s/%s/training_embedding.mat'%(parameters.projectPath, parameters.method))['trainingEmbedding']\n",
        "m = np.abs(trainy).max()\n",
        "\n",
        "\n",
        "sigma=2.0\n",
        "_, xx, density = mmpy.findPointDensity(trainy, sigma, 511, [-m-20, m+20])\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12,6))\n",
        "axes[0].scatter(trainy[:,0], trainy[:,1], marker='.', c=np.arange(trainy.shape[0]), s=1)\n",
        "axes[0].set_xlim([-m-20, m+20])\n",
        "axes[0].set_ylim([-m-20, m+20])\n",
        "\n",
        "axes[1].imshow(density, cmap=mmpy.gencmap(), extent=(xx[0], xx[-1], xx[0], xx[-1]), origin='lower')\n",
        "plt.savefig(\"tmp3.png\",dpi=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-B_oiewMXAC"
      },
      "source": [
        "On the left, we see a scatter plot and on the right, we see a Gaussian kernel convolved density estimation of these points. Does it surprise you? What does changing the sigma value do?  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW5jndTkW1of"
      },
      "source": [
        "# 6.&nbsp; Finding embeddings for all data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdCW8Y309RXu"
      },
      "source": [
        "Now, we can find embeddings for our entire dataset! We'll use the `mmpy.findEmbeddings` function which requires the training set and the 2-d embeddings we find in the last step, and the high-d 'projections' time series for each dataset. We'll save the obtained embeddings for each dataset neatly in the Projections folder so that we can reference them later.\n",
        "\n",
        "**Running time** : TSNE 19 mins | UMAP 3 mins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MB84yPqS8u89"
      },
      "outputs": [],
      "source": [
        "# #tsne takes 19 mins\n",
        "# tall = time.time()\n",
        "\n",
        "# import h5py\n",
        "# tfolder = parameters.projectPath+'/%s/'%parameters.method\n",
        "\n",
        "# # Loading training data\n",
        "# with h5py.File(tfolder + 'training_data.mat', 'r') as hfile:\n",
        "#     trainingSetData = hfile['trainingSetData'][:].T\n",
        "\n",
        "# # Loading training embedding\n",
        "# with h5py.File(tfolder+ 'training_embedding.mat', 'r') as hfile:\n",
        "#     trainingEmbedding= hfile['trainingEmbedding'][:].T\n",
        "\n",
        "# if parameters.method == 'TSNE':\n",
        "#     zValstr = 'zVals' \n",
        "# else:\n",
        "#     zValstr = 'uVals'\n",
        "\n",
        "# projectionFiles = glob.glob(parameters.projectPath+'/Projections/*pcaModes.mat')\n",
        "# for i in range(len(projectionFiles)):\n",
        "#     print('Finding Embeddings')\n",
        "#     t1 = time.time()\n",
        "#     print('%i/%i : %s'%(i+1,len(projectionFiles), projectionFiles[i]))\n",
        "\n",
        "\n",
        "#     # Skip if embeddings already found.\n",
        "#     if os.path.exists(projectionFiles[i][:-4] +'_%s.mat'%(zValstr)):\n",
        "#         print('Already done. Skipping.\\n')\n",
        "#         continue\n",
        "\n",
        "#     # load projections for a dataset\n",
        "#     projections = hdf5storage.loadmat(projectionFiles[i])['projections']\n",
        "\n",
        "#     # Find Embeddings\n",
        "#     zValues, outputStatistics = mmpy.findEmbeddings(projections,trainingSetData,trainingEmbedding,parameters,projectionFiles[i])\n",
        "\n",
        "#     # Save embeddings\n",
        "#     hdf5storage.write(data = {'zValues':zValues}, path = '/', truncate_existing = True,\n",
        "#                     filename = projectionFiles[i][:-4]+'_%s.mat'%(zValstr), store_python_metadata = False,\n",
        "#                       matlab_compatible = True)\n",
        "    \n",
        "#     # Save output statistics\n",
        "#     with open(projectionFiles[i][:-4] + '_%s_outputStatistics.pkl'%(zValstr), 'wb') as hfile:\n",
        "#         pickle.dump(outputStatistics, hfile)\n",
        "\n",
        "#     del zValues,projections,outputStatistics\n",
        "\n",
        "# print('All Embeddings Saved in %i seconds!'%(time.time()-tall))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "files = glob.glob(parameters.projectPath+'/Projections/*_%s.mat'%(\"zVals\"))\n",
        "ally = hdf5storage.loadmat(files[0])['zValues']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlhFOt0-G_cW"
      },
      "source": [
        "We can visualize the obtained embeddings by calling the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMHW7yDeJIy_"
      },
      "outputs": [],
      "source": [
        "# load all the embeddings\n",
        "# for i in glob.glob(parameters.projectPath+'/Projections/*zVals.mat'):\n",
        "  # ally = hdf5storage.loadmat(i)['zValues']\n",
        "\n",
        "m = np.abs(ally).max()\n",
        "\n",
        "sigma=2.0\n",
        "_, xx, density = mmpy.findPointDensity(ally, sigma, 511, [-m-10, m+10])\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12,6))\n",
        "axes[0].scatter(ally[:,0], ally[:,1], marker='.', c=np.arange(ally.shape[0]), s=1)\n",
        "axes[0].set_xlim([-m-20, m+20])\n",
        "axes[0].set_ylim([-m-20, m+20])\n",
        "\n",
        "axes[1].imshow(density, cmap=mmpy.gencmap(), extent=(xx[0], xx[-1], xx[0], xx[-1]), origin='lower')\n",
        "plt.savefig(\"tmp4.png\",dpi=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLoOcHS0OKbr"
      },
      "source": [
        "# 7.&nbsp; Watershed transform on the density map. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkPqF-zDYANq"
      },
      "source": [
        "There is another handy function in `motionmapperpy` called `findWatershedRegions`. This will do an iterative watershed transform on the behavioral density map until the given `minimum_regions` are found in the density map.\n",
        "\n",
        "It saves watershed transformed output of the embedding in `project_director/UMAP/zVals_wShed_groups.mat` file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50zDsiEPLw4s"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# startsigma = 4.2 if parameters.method == 'TSNE' else 1.0\n",
        "# mmpy.findWatershedRegions(parameters, minimum_regions=10, startsigma=startsigma, pThreshold=[0.33, 0.67],\n",
        "#                      saveplot=True, endident = '*_pcaModes.mat')\n",
        "mmpy.findWatershedRegions(\n",
        "    parameters,\n",
        "    minimum_regions=20,\n",
        "    startsigma=1,\n",
        "    pThreshold=[0.33, .67],\n",
        "    saveplot=True,\n",
        "    endident=\"*-pcaModes.mat\",\n",
        ")\n",
        "# from IPython.display import Image\n",
        "# Image(glob.glob('%s/%s/zWshed*.png'%(parameters.projectPath, parameters.method))[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY-yeTfGNok7"
      },
      "source": [
        "# 8.&nbsp; Ethograms and videos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-m-s9GpYolw"
      },
      "source": [
        "We can now create ethograms using the watershed region time series created in the last step. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IjHvBQ2Begp"
      },
      "outputs": [],
      "source": [
        "wshedfile = hdf5storage.loadmat('%s/%s/zVals_wShed_groups.mat'%(parameters.projectPath, parameters.method))\n",
        "\n",
        "wregs = wshedfile['watershedRegions'].flatten()\n",
        "ethogram = np.zeros((wregs.max()+1, len(wregs)))\n",
        "\n",
        "for wreg in range(1, wregs.max()+1):\n",
        "  ethogram[wreg, np.where(wregs==wreg)[0]] = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "ethogram_2 = np.split(ethogram.T, np.cumsum(wshedfile['zValLens'][0].flatten())[:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "[ethogram.shape for ethogram in ethogram]\n",
        "wshedfile['zValNames'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "[e[0:1000,:].shape for e in ethogram_2[0:4]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "fig, axes = plt.subplots(4, 1, figsize=(20,10))\n",
        "ethogram_subset = [e[0:1000,:] for e in ethogram_2[0:4]]\n",
        "\n",
        "for e, name, ax in zip(ethogram_subset, wshedfile['zValNames'][0], axes.flatten()):\n",
        "  print(e.shape)\n",
        "  ax.imshow(e.T, aspect='auto', cmap=mmpy.gencmap())\n",
        "  ax.set_title(name[0][0])\n",
        "  ax.set_yticks([i for i in range(1, wregs.max()+1, 4)])\n",
        "  ax.set_yticklabels(['Region %i'%(j+1) for j in range(1, wregs.max()+1, 4)])\n",
        "\n",
        "  # xticklocs = [6000*i for i in range(3)]\n",
        "  # ax.set_xticks(xticklocs)\n",
        "  # ax.set_xticklabels([j/(6000) for j in xticklocs])\n",
        "\n",
        "ax.set_xlabel('Time (min)')\n",
        "plt.savefig(\"tmp5.png\",dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wshedfile = hdf5storage.loadmat('%s/%s/zVals_wShed_groups.mat'%(parameters.projectPath, parameters.method))\n",
        "\n",
        "try:\n",
        "  tqdm._instances.clear()\n",
        "except:\n",
        "  pass\n",
        "\n",
        "# fig, axes = plt.subplots(1, 2, figsize=(10,5))\n",
        "# zValues = wshedfile['zValues']\n",
        "# m = np.abs(zValues).max()\n",
        "\n",
        "\n",
        "# sigma=1.0\n",
        "# _, xx, density = mmpy.findPointDensity(zValues, sigma, 511, [-m-10, m+10])\n",
        "# axes[0].imshow(density, cmap=mmpy.gencmap(), extent=(xx[0], xx[-1], xx[0], xx[-1]), origin='lower')\n",
        "# axes[0].axis('off')\n",
        "# axes[0].set_title('Method : %s'%parameters.method)\n",
        "# sc = axes[0].scatter([],[],marker='o', color='k', s=500)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 1, figsize=(5,5))\n",
        "zValues = wshedfile['zValues']\n",
        "m = np.abs(zValues).max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sigma=1.0\n",
        "_, xx, density = mmpy.findPointDensity(zValues, sigma, 511, [-m-10, m+10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 1, figsize=(5,5))\n",
        "axes.imshow(density, cmap=mmpy.gencmap(), extent=(xx[0], xx[-1], xx[0], xx[-1]), origin='lower')\n",
        "axes.axis('off')\n",
        "axes.set_title('Method : %s'%parameters.method)\n",
        "sc = axes.scatter([],[],marker='o', color='k', s=500)\n",
        "\n",
        "def animate(t):\n",
        "#   t = int(t*clips[h5ind].fps)+tstart\n",
        "#   axes[1].clear()\n",
        "#   im = axes[1].imshow(clips[h5ind].get_frame(t/clips[h5ind].fps), cmap='Greys', origin='lower')\n",
        "#   for conn in connections:\n",
        "#       axes[1].plot(h5s[h5ind][t, conn, 0], h5s[h5ind][t, conn, 1], 'k-')\n",
        "#   axes[1].axis('off')\n",
        "  sc.set_offsets(zValues[int(t)])\n",
        "  return mplfig_to_npimage(fig) #im, ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anim = VideoClip(animate, duration=100) # will throw memory error for more than 100.\n",
        "plt.close()\n",
        "anim.ipython_display(fps=100, loop=True, autoplay=True, maxduration=120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxrwhMtMaaCa"
      },
      "source": [
        "## 8.1 Visualize behavioral map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9q58dYlIODxJ"
      },
      "source": [
        "Run the below code to see the behavioral map in action. \n",
        "\n",
        "This may take **2 minutes** to run. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdjnI94ct-I_"
      },
      "outputs": [],
      "source": [
        "wshedfile = hdf5storage.loadmat('%s/%s/zVals_wShed_groups.mat'%(parameters.projectPath, parameters.method))\n",
        "\n",
        "try:\n",
        "  tqdm._instances.clear()\n",
        "except:\n",
        "  pass\n",
        "\n",
        "fig, axes = plt.subplots(1, 1, figsize=(5,5))\n",
        "zValues = wshedfile['zValues']\n",
        "m = np.abs(zValues).max()\n",
        "\n",
        "\n",
        "sigma=1.0\n",
        "_, xx, density = mmpy.findPointDensity(zValues, sigma, 511, [-m-10, m+10])\n",
        "axes.imshow(density, cmap=mmpy.gencmap(), extent=(xx[0], xx[-1], xx[0], xx[-1]), origin='lower')\n",
        "axes.axis('off')\n",
        "axes.set_title('Method : %s'%parameters.method)\n",
        "sc = axes.scatter([],[],marker='o', color='k', s=500)\n",
        "\n",
        "h5ind = 0\n",
        "tstart = 0\n",
        "# connections = [np.arange(6,10), np.arange(10,14), np.arange(14,18), np.arange(18,22), np.arange(22,26), np.arange(26,30),\n",
        "#               [2,0,1],[0,3,4,5], [31,3,30]]\n",
        "\n",
        "def animate(t):\n",
        "  # t = int(t*clips[h5ind].fps)+tstart\n",
        "  # axes[1].clear()\n",
        "  # im = axes[1].imshow(clips[h5ind].get_frame(t/clips[h5ind].fps), cmap='Greys', origin='lower')\n",
        "  # for conn in connections:\n",
        "  #     axes[1].plot(h5s[h5ind][t, conn, 0], h5s[h5ind][t, conn, 1], 'k-')\n",
        "  # axes[1].axis('off')\n",
        "  sc.set_offsets(zValues[t])\n",
        "  return mplfig_to_npimage(fig) #im, ax\n",
        "\n",
        "\n",
        "anim = VideoClip(animate, duration=2) # will throw memory error for more than 100.\n",
        "plt.close()\n",
        "anim.ipython_display(fps=15, loop=True, autoplay=True, maxduration=120)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8X9SvyLia_hT"
      },
      "source": [
        "At this point, you know everything you need to know to create a behavioral map for a set of datasets. But this is where we can actually start doing some science! \n",
        "\n",
        "Open the project directory on the left pane. We should see some files in *Fly_Leap_mmpy/TSNE* or Fly_Leap_mmpy/UMAP folder. The 2-dimensional embeddings of all the files we've used for this project can be found in the **zVals_wShed_groups.mat** file which can be opened using hdf5storage in Python (as we did in the previous cell) or natively in MATLAB. This is where we can start doing some science!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVrrrOmu8Ywb"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.imshow(\n",
        "wshedfile['density'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOf3NnCq94SH"
      },
      "outputs": [],
      "source": [
        "wshedfile['zValNames']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDoZvt6Z-RYv"
      },
      "outputs": [],
      "source": [
        "wshedfile['zValLens']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nJgioFq9mdx"
      },
      "outputs": [],
      "source": [
        "wshedfile['watershedRegions'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtKsrjks-KfN"
      },
      "outputs": [],
      "source": [
        "\n",
        "wshedfile['zValues'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j66bqndnevGe"
      },
      "outputs": [],
      "source": [
        "list(wshedfile.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWRss0HMefip"
      },
      "source": [
        "## 8.2 Create region videos\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzuQ3TLgcIDJ"
      },
      "source": [
        "Now we'll try to create region videos - we'll pick contiguous time points that belong in one watershed region, and see what the animals is doing at those times by creating a movie.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFqSm9a8FZJr"
      },
      "outputs": [],
      "source": [
        "def makeGroupsAndSegments(watershedRegions, zValLens, min_length=10, max_length=100):\n",
        "\n",
        "  inds = np.zeros_like(watershedRegions)\n",
        "  start = 0\n",
        "  for l in zValLens:\n",
        "      inds[start:start + l] = np.arange(l)\n",
        "      start += l\n",
        "  vinds = np.digitize(np.arange(watershedRegions.shape[0]), bins=np.concatenate([[0], np.cumsum(zValLens)]))\n",
        "\n",
        "  splitinds = np.where(np.diff(watershedRegions, axis=0) != 0)[0] + 1\n",
        "  inds = [i for i in np.split(inds, splitinds) if len(i) > min_length and len(i) < max_length]\n",
        "  wregs = [i[0] for i in np.split(watershedRegions, splitinds) if len(i) > min_length and len(i) < max_length]\n",
        "\n",
        "  vinds = [i for i in np.split(vinds, splitinds) if len(i) > min_length and len(i) < max_length]\n",
        "  groups = [np.empty((0, 3), dtype=int)] * watershedRegions.max()\n",
        "\n",
        "  for wreg, tind, vind in zip(wregs, inds, vinds):\n",
        "      if np.all(vind == vind[0]):\n",
        "          groups[wreg - 1] = np.concatenate(\n",
        "              [groups[wreg - 1], np.array([vind[0], tind[0] + 1, tind[-1] + 1])[None, :]])\n",
        "  groups = np.array([[g] for g in groups])\n",
        "  return groups\n",
        "\n",
        "\n",
        "def makeregionvideo(region, parameters, wshedfile):\n",
        "\n",
        "  \n",
        "  animfps=50.0\n",
        "  subs=2\n",
        "  submaxframes = 500\n",
        "  \n",
        "  \n",
        "  groups = makeGroupsAndSegments(wshedfile['watershedRegions'][0], wshedfile['zValLens'][0])\n",
        "  nregs = len(groups)\n",
        "\n",
        "  region = region-1\n",
        "  \n",
        "  outputdir = '%s/%s/region_videos_%i/'%(parameters.projectPath, parameters.method, nregs)\n",
        "  if not os.path.exists(outputdir):\n",
        "    os.mkdir(outputdir)\n",
        "  groups = groups-1\n",
        "  print('[Region %i] Starting'%(region+1))\n",
        "\n",
        "  if os.path.isfile(outputdir + 'regions_' + '%.3i' % (region + 1) + '.mp4'):\n",
        "      print('[Region %i] Already present. '%(region+1))\n",
        "      return \n",
        "    \n",
        "  tqdm._instances.clear()\n",
        "\n",
        "  if not groups[region][0].shape[0] or groups[region][0].shape[0] == 1:\n",
        "      print('[Region %i] No frames in groups.'%(region+1))\n",
        "      return\n",
        "\n",
        "  nframes = np.atleast_1d(np.diff(groups[region][0][:, 1:], axis=1).squeeze())\n",
        "  if np.sum(nframes < submaxframes) == 0:\n",
        "      print('[Region %i] All frames sequences more than length %i.'%\n",
        "            (region+1, submaxframes))\n",
        "      return\n",
        "\n",
        "  nplots = min(subs * subs, np.sum(nframes < submaxframes))\n",
        "  longinds = np.where(nframes < submaxframes)[0]\n",
        "  selectedclips = longinds[np.argsort(nframes[longinds])[::-1]][:nplots]\n",
        "\n",
        "  vidindslist = groups[region][0][selectedclips, 0]\n",
        "  framestoplot = np.array([np.arange(groups[region][0][i, 1], groups[region][0][i, 2]) for i in selectedclips])\n",
        "  maxsize = max([i.shape[0] for i in framestoplot])\n",
        "\n",
        "  print('[Region %i] Making region video...'%(region+1))\n",
        "\n",
        "\n",
        "  subx = max(2, int(np.ceil(np.sqrt(nplots))))\n",
        "  fig, axes = plt.subplots(subx, subx, figsize=(12, 12))\n",
        "  fig.subplots_adjust(0, 0, 1.0, 1.0, 0.0, 0.0)\n",
        "\n",
        "  def make_frame(t):\n",
        "      j_ = int(t * animfps)\n",
        "      for i in range(subx * subx):\n",
        "\n",
        "          ax = axes[i // subx, i % subx]\n",
        "          ax.clear()\n",
        "          ax.axis('off')\n",
        "          if i >= nplots:\n",
        "              continue\n",
        "          j = j_ % len(framestoplot[i])\n",
        "          clip = clips[vidindslist[i]]\n",
        "          ax.imshow(clip.get_frame(framestoplot[i][j]/clip.fps),\n",
        "                    cmap='Greys_r', origin='lower')\n",
        "      return mplfig_to_npimage(fig)\n",
        "\n",
        "  try:\n",
        "      tqdm._instances.clear()\n",
        "  except:\n",
        "      pass\n",
        "  \n",
        "  t1 = time.time()\n",
        "  animation = VideoClip(make_frame, duration=maxsize / animfps)\n",
        "\n",
        "  animation.write_videofile(outputdir + 'regions_' + '%.3i' % (region + 1) + '.mp4', fps=animfps, audio=False,\n",
        "                            threads=1)\n",
        "  \n",
        "  print('[Region %i] %i seconds, Saved at %s'%(region+1, time.time()-t1,  outputdir + 'regions_' + '%.3i' % (region + 1) + '.mp4'))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8KvtmGD-xex"
      },
      "outputs": [],
      "source": [
        "makeregionvideo(10, parameters, wshedfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPAVaIKzY1m6"
      },
      "outputs": [],
      "source": [
        "# This creates region videos for all the region. This can take a while to run so be careful!\n",
        "wmax = wshedfile['watershedRegions'].max()\n",
        "print(wmax)\n",
        "for i in range(1, wmax+1):\n",
        "    makeregionvideo(i, parameters, wshedfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64hriJsbbPOE"
      },
      "outputs": [],
      "source": [
        "# Set region below to see your video.\n",
        "region = 10\n",
        "\n",
        "print('Region %i'%region)\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "outputdir = '%s/%s/region_vidoes_%i/'%(parameters.projectPath, parameters.method, wshedfile['watershedRegions'].max())\n",
        "mp4 = open(outputdir + 'regions_' + '%.3i' % (region) + '.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls loop autoplay>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sHy6AF8YY25"
      },
      "source": [
        "\n",
        "\n",
        "You can also zip your project folder by calling \n",
        "```!zip -r Fly_Leap_mmpy.zip Fly_Leap_mmpy``` \n",
        "and download the folder on your local computer to play around with it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySony2raayOg"
      },
      "outputs": [],
      "source": [
        "# !zip -r Fly_Leap_mmpy.zip Fly_Leap_mmpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl1TfHhQXAEE"
      },
      "source": [
        "# Transition Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_twbCv0yazsF"
      },
      "outputs": [],
      "source": [
        "wregs = wshedfile['watershedRegions'][0]\n",
        "wregs = np.split(wregs, np.cumsum(wshedfile['zValLens'][0])[:-1])\n",
        "transitions = [mmpy.demoutils.getTransitions(w[w>0]) for w in wregs]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-FfsTN-YkKY"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 4, figsize=(16,5))\n",
        "\n",
        "statevals = np.arange(1,wshedfile['watershedRegions'].max()+2)\n",
        "for ax, d in zip(axes.flatten(), [1, 10, 100, 1000]):\n",
        "    F = mmpy.demoutils.makeTransitionMatrix(np.concatenate(transitions), d)\n",
        "    ax.imshow(F, cmap='PuRd', extent=(statevals[0], statevals[-1], statevals[0], statevals[-1]))\n",
        "    ax.set_xlabel('Initial State') \n",
        "    ax.set_ylabel('Final State')\n",
        "plt.savefig('transition_matrix.png', dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bRLtqCyYeZ_"
      },
      "outputs": [],
      "source": [
        "_ = mmpy.demoutils.plotLaggedEigenvalues(transitions)\n",
        "plt.savefig('eigenvalues.png', dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IExLdacW5Uf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.7.11 ('sleap_dev')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "177c836934b6a63d57a075b5cc3f7812a3de8a98495a556647184ecb20fdf5fb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
